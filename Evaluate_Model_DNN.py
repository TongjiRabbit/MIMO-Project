import sys
import os
import torch
import torch.nn as nn
import scipy.io as sio
import numpy as np
from collections import defaultdict

# ================= é…ç½®åŒºåŸŸ =================
MODEL_PATH = 'DFDCA_DNN_Model_TrainBatch1to5_-10to20db_gap5db_4096hidden_500epoch.pth'                  # è®­ç»ƒå¥½çš„æ¨¡å‹

DATA_DIR = r'D:\CodeSpace\CodeOfMMSE_xUser_re_OnlyTrainToTrain\Data'
TEST_FILES_NAME = [
'TrainData_Batch_1.mat',
'TrainData_Batch_2.mat',
]
TEST_FILES = [os.path.join(DATA_DIR, f) for f in TEST_FILES_NAME]

RESULT_DIR = r'D:\CodeSpace\CodeOfMMSE_xUser_re_OnlyTrainToTrain\Result_P'
OUTPUT_FILE_NAME = 'DFDCA_Evaluation_Results_TrainBatch1to5_test1to2_4096hidden_500epoch.mat'        # å¯¼å‡ºçš„ç»“æœæ–‡ä»¶
OUTPUT_FILE = os.path.join(RESULT_DIR, OUTPUT_FILE_NAME)

HIDDEN_SIZE = 4096                                  # å¿…é¡»ä¸ Model.py ä¸€è‡´
DEVICE = torch.device("cuda" if torch.cuda.is_available() else "cpu")
# ===========================================

# 1. å®šä¹‰ç½‘ç»œç»“æ„ (å¿…é¡»ä¸è®­ç»ƒä»£ç å®Œå…¨ä¸€è‡´)
class ChannelNet(nn.Module):
    def __init__(self, input_dim, output_dim):
        super(ChannelNet, self).__init__()
        self.layer1 = nn.Sequential(
            nn.Linear(input_dim, HIDDEN_SIZE),
            nn.BatchNorm1d(HIDDEN_SIZE),
            nn.ReLU()
        )
        self.layer2 = nn.Sequential(
            nn.Linear(HIDDEN_SIZE, 4096),
            nn.BatchNorm1d(4096),
            nn.ReLU()
        )
        self.output_layer = nn.Linear(4096, output_dim)

    def forward(self, x):
        x = self.layer1(x)
        x = self.layer2(x)
        return self.output_layer(x)

def calculate_metrics(p_pred_complex, p_true_complex):
    """ è®¡ç®—å•ä¸ªæ ·æœ¬çš„ MSE å’Œ ä½™å¼¦ç›¸ä¼¼åº¦ """
    # å±•å¹³ä¸ºå‘é‡
    pred_flat = p_pred_complex.flatten()
    true_flat = p_true_complex.flatten()

    # 1. MSE è®¡ç®—
    diff = pred_flat - true_flat
    mse = np.mean(np.abs(diff) ** 2)

    # 2. ä½™å¼¦ç›¸ä¼¼åº¦è®¡ç®— (è€ƒè™‘å¤æ•°å…±è½­)
    # Sim = |a . b*| / (|a| * |b|)
    dot_product = np.abs(np.vdot(pred_flat, true_flat)) 
    norm_pred = np.linalg.norm(pred_flat)
    norm_true = np.linalg.norm(true_flat)
    
    if norm_pred == 0 or norm_true == 0:
        similarity = 0.0
    else:
        similarity = dot_product / (norm_pred * norm_true)

    return mse, similarity


def _extract_scalar(sample, field_name, default=None):
    if field_name not in sample.dtype.names:
        return default
    try:
        return float(np.array(sample[field_name]).flat[0])
    except Exception:
        return default


def _extract_user_indices(sample, usrnum=None):
    if 'User_Indices' not in sample.dtype.names:
        return None
    arr = np.array(sample['User_Indices']).astype(np.int64, copy=False).reshape(-1)
    if usrnum is not None and arr.size != usrnum:
        if arr.size > usrnum:
            arr = arr[:usrnum]
        else:
            arr = np.pad(arr, (0, usrnum - arr.size), mode='constant', constant_values=0)
    return arr


def normalize_p_pred_flat_ri(y_pred_flat_ri, usrnum, frenum, eps=1e-9):
    """å¯¹é¢„æµ‹Påšé€ç”¨æˆ·è¡ŒåŠŸç‡å½’ä¸€åŒ–ï¼›è¾“å…¥/è¾“å‡ºå‡ä¸ºå±•å¹³RIæ‹¼æ¥å‘é‡ã€‚"""
    half = y_pred_flat_ri.size // 2
    p_real = y_pred_flat_ri[:half].reshape((usrnum, frenum), order='C')
    p_imag = y_pred_flat_ri[half:].reshape((usrnum, frenum), order='C')
    p_complex = p_real + 1j * p_imag

    for i in range(usrnum):
        current_p = p_complex[i, :]
        current_power = float(np.sum(np.abs(current_p) ** 2))
        if current_power > eps:
            p_complex[i, :] = current_p * np.sqrt(float(frenum) / current_power)

    p_real_norm = np.real(p_complex).reshape(-1, order='C')
    p_imag_norm = np.imag(p_complex).reshape(-1, order='C')
    return np.concatenate((p_real_norm, p_imag_norm))

def main():
    print(f"=== DFDCA æ¨¡å‹éªŒè¯ä¸æ•°æ®å¯¼å‡º ===")
    print(f"è®¾å¤‡: {DEVICE}")

    # --- 1. æ‰‹åŠ¨æŒ‡å®šå¹¶æ‹¼æ¥å¤šä¸ªæ•°æ®æºï¼ˆæŒ‰é¡ºåºæ‹¼æ¥ï¼›ç¡®ä¿å…ƒä¿¡æ¯ä¸€ä¸€å¯¹åº”ï¼‰ ---
    test_files = list(TEST_FILES)

    if not test_files:
        print("âŒ é”™è¯¯: TEST_FILES ä¸ºç©ºï¼Œè¯·åœ¨è„šæœ¬é¡¶éƒ¨æ‰‹åŠ¨å¡«å†™å¾…è¯„ä¼°çš„ .mat æ–‡ä»¶ååˆ—è¡¨ã€‚")
        return

    print(f"ğŸ“‚ å¾…è¯„ä¼°æ–‡ä»¶æ•°: {len(test_files)}")
    for f in test_files:
        print(f"   - {f}")
    
    # åˆå¹¶æ‰€æœ‰ Batch_Buffer
    all_samples = []
    total_samples = 0
    
    for test_file in test_files:
        try:
            if not os.path.exists(test_file):
                print(f"   âŒ {test_file}: æ–‡ä»¶ä¸å­˜åœ¨")
                continue
            mat_data = sio.loadmat(test_file)
            if 'Batch_Buffer' not in mat_data:
                print(f"   âŒ {test_file}: ä¸åŒ…å« Batch_Buffer")
                continue
            test_buffer = mat_data['Batch_Buffer']
            num_batch_samples = test_buffer.shape[1]
            
            # æå–å½“å‰æ–‡ä»¶çš„æ‰€æœ‰æ ·æœ¬
            for i in range(num_batch_samples):
                all_samples.append(test_buffer[0, i])
            
            total_samples += num_batch_samples
            print(f"   âœ… {test_file}: {num_batch_samples} ä¸ªæ ·æœ¬")
        except Exception as e:
            print(f"   âŒ {test_file}: è¯»å–å¤±è´¥ - {e}")
            continue
    
    if total_samples == 0:
        print(f"âŒ é”™è¯¯: æœªæˆåŠŸåŠ è½½ä»»ä½•æ ·æœ¬")
        return
    
    print(f"\nâœ… æˆåŠŸåˆå¹¶ {total_samples} ä¸ªæµ‹è¯•æ ·æœ¬")

    # --- 2. å‡†å¤‡æ¨¡å‹ ---
    # è¯»å–ç¬¬ä¸€ä¸ªæ ·æœ¬ä»¥ç¡®å®šè¾“å…¥è¾“å‡ºç»´åº¦
    sample_0 = all_samples[0]
    input_dim = sample_0['R_Real'].size + sample_0['R_Imag'].size
    output_dim = sample_0['P_Real'].size + sample_0['P_Imag'].size
    
    print(f"\nğŸ”§ æ¨¡å‹é…ç½®:")
    print(f"   è¾“å…¥ç»´åº¦: {input_dim}, è¾“å‡ºç»´åº¦: {output_dim}")
    print(f"   éšå±‚å®½åº¦: {HIDDEN_SIZE}")

    model = ChannelNet(input_dim, output_dim).to(DEVICE)
    
    if not os.path.exists(MODEL_PATH):
        print(f"âŒ é”™è¯¯: æ‰¾ä¸åˆ°æ¨¡å‹æ–‡ä»¶ {MODEL_PATH}")
        return

    model.load_state_dict(torch.load(MODEL_PATH, map_location=DEVICE))
    model.eval()
    print("âœ… æ¨¡å‹æƒé‡åŠ è½½å®Œæ¯•")

    # --- 3. æ¨ç†ä¸æŒ‡æ ‡è®¡ç®— + å¯¼å‡ºæ‰€éœ€åŸå§‹æ•°æ® ---
    # ä½¿ç”¨å­—å…¸å­˜å‚¨æŒ‰ SNR åˆ†ç»„çš„ç»“æœ
    results_by_snr = defaultdict(lambda: {'mse': [], 'sim': [], 'power': []})

    # é€æ ·æœ¬å¯¼å‡ºï¼ˆä¸ all_samples é¡ºåºä¸€ä¸€å¯¹åº”ï¼‰
    p_pred_flat_ri_list = []
    p_true_flat_ri_list = []
    snr_db_list = []
    noise_power_list = []
    group_id_list = []
    user_indices_list = []

    print("\nå¼€å§‹æ¨ç†è®¡ç®—...")
    with torch.no_grad():
        for i, sample in enumerate(all_samples):
            snr_val = _extract_scalar(sample, 'SNR_dB', default=np.nan)

            # # è¿‡æ»¤é€»è¾‘ï¼šåªæµ‹ 15 å’Œ 20 dB
            # if snr_val < 14:
            #     continue



            # è·å–æ•°æ®
            r_real = sample['R_Real']
            r_imag = sample['R_Imag']
            p_real_true = sample['P_Real']
            p_imag_true = sample['P_Imag']

            usrnum = int(p_real_true.shape[0]) if hasattr(p_real_true, 'shape') and np.ndim(p_real_true) >= 2 else 10
            total_p = int(np.size(p_real_true))
            if hasattr(p_real_true, 'shape') and np.ndim(p_real_true) >= 2:
                frenum = int(p_real_true.shape[1])
            else:
                if usrnum <= 0 or total_p % usrnum != 0:
                    raise ValueError(f"æ— æ³•ä» P_Real æ¨æ–­ç»´åº¦: size={total_p}, usrnum={usrnum}")
                frenum = int(total_p // usrnum)
            
    
            # é¢„å¤„ç†è¾“å…¥
            x_vec = np.concatenate((r_real.flatten(), r_imag.flatten()))
            x_tensor = torch.FloatTensor(x_vec).unsqueeze(0).to(DEVICE)

            #snrä½œä¸ºè¾“å…¥ç‰¹å¾æ—¶é‡‡ç”¨
            # x_feat = np.concatenate((r_real.flatten(), r_imag.flatten()))
            # snr_norm = snr_val / 20.0
            # x_vec = np.append(x_feat, snr_norm)
            # x_tensor = torch.FloatTensor(x_vec).unsqueeze(0).to(DEVICE)

            # æ¨¡å‹é¢„æµ‹
            y_pred = model(x_tensor).cpu().numpy().squeeze().astype(np.float64, copy=False)

            # --- é¢„æµ‹PåŠŸç‡å½’ä¸€åŒ–ï¼ˆé€ç”¨æˆ·è¡Œï¼‰ ---
            y_pred_norm = normalize_p_pred_flat_ri(y_pred, usrnum=usrnum, frenum=frenum)

            # åå¤„ç†ï¼šç”¨äºæŒ‡æ ‡è®¡ç®—çš„å¤æ•°å‘é‡ï¼ˆå±•å¹³ï¼‰
            mid = len(y_pred_norm) // 2
            p_pred_complex = y_pred_norm[:mid] + 1j * y_pred_norm[mid:]
            p_true_complex = p_real_true.flatten(order='C') + 1j * p_imag_true.flatten(order='C')

            # è®¡ç®—æŒ‡æ ‡
            mse, sim = calculate_metrics(p_pred_complex, p_true_complex)
            
            # --- æ–°å¢ï¼šè®¡ç®—çœŸå®æ ‡ç­¾çš„åŠŸç‡ (æ¨¡çš„å¹³æ–¹) ---
            p_true_power = np.mean(np.abs(p_true_complex)**2)

            # --- æ”¶é›†å¯¼å‡ºæ•°æ®ï¼ˆä¿æŒå±•å¹³ï¼Œä¸å¤åŸä¸ºçŸ©é˜µï¼‰ ---
            p_pred_flat_ri_list.append(y_pred_norm)
            p_true_flat_ri_list.append(
                np.concatenate((p_real_true.flatten(order='C'), p_imag_true.flatten(order='C'))).astype(np.float64, copy=False)
            )
            snr_db_list.append(snr_val)
            noise_power_list.append(_extract_scalar(sample, 'Noise_Power', default=np.nan))
            group_id_list.append(_extract_scalar(sample, 'Group_ID', default=np.nan))
            user_idx = _extract_user_indices(sample, usrnum=usrnum)
            user_indices_list.append(user_idx if user_idx is not None else np.zeros((usrnum,), dtype=np.int64))

            # å­˜å…¥åˆ—è¡¨
            results_by_snr[snr_val]['mse'].append(mse)
            results_by_snr[snr_val]['sim'].append(sim)
            results_by_snr[snr_val]['power'].append(p_true_power) # <--- æ–°å¢è¿™è¡Œ

            if (i + 1) % 500 == 0:
                print(f"   å·²å¤„ç† {i + 1}/{total_samples} ...")

    # --- 4. æ±‡æ€»æ•°æ® ---
    snr_list = sorted(results_by_snr.keys())
    avg_mse_list = []
    avg_sim_list = []
    
    # è¿™é‡Œä¹Ÿå¯ä»¥é€‰æ‹©ä¿å­˜æ‰€æœ‰æ ·æœ¬çš„åŸå§‹æ•°æ®ï¼Œä»¥ä¾¿ç”»ç®±çº¿å›¾ç­‰ï¼Œ
    # ä½†é€šå¸¸ç”»æ€§èƒ½æ›²çº¿åªéœ€è¦å¹³å‡å€¼ã€‚è¿™é‡Œæˆ‘ä»¬ä¸¤è€…éƒ½å‡†å¤‡ã€‚
    raw_mse_data = [] # è¿™æ˜¯ä¸€ä¸ª cell ç±»ä¼¼çš„ç»“æ„åˆ—è¡¨
    raw_sim_data = []

    print("\n=== éªŒè¯ç»“æœ (å¹³å‡å€¼) ===")
    print(f"{'SNR (dB)':<10} | {'MSE':<10} | {'Similarity':<10}| {'True Power':<10}")
    print("-" * 50)

    for snr in snr_list:
        mses = results_by_snr[snr]['mse']
        sims = results_by_snr[snr]['sim']
        pwrs = results_by_snr[snr]['power'] # <--- è·å–åŠŸç‡åˆ—è¡¨
        
        avg_mse = np.mean(mses)
        avg_sim = np.mean(sims)
        avg_pwr = np.mean(pwrs)             # <--- è®¡ç®—å¹³å‡åŠŸç‡
        
        avg_mse_list.append(avg_mse)
        avg_sim_list.append(avg_sim)
        
        # æ”¶é›†åŸå§‹æ•°æ®ä»¥ä¾¿å¯¼å‡º (numpy array)
        raw_mse_data.append(np.array(mses))
        raw_sim_data.append(np.array(sims))

        print(f"{snr:<10} | {avg_mse:<10.5f} | {avg_sim:<10.5f}| {avg_pwr:<10.5f}")

    # --- 5. å¯¼å‡ºåˆ° .mat æ–‡ä»¶ ---
    p_pred_flat_ri = np.stack(p_pred_flat_ri_list, axis=0) if p_pred_flat_ri_list else np.zeros((0, output_dim))
    p_true_flat_ri = np.stack(p_true_flat_ri_list, axis=0) if p_true_flat_ri_list else np.zeros((0, output_dim))
    user_indices = np.stack(user_indices_list, axis=0) if user_indices_list else np.zeros((0, 0), dtype=np.int64)

    export_data = {
        # åŸºç¡€é…ç½®
        'Model_Path': MODEL_PATH,
        'Input_Dim': np.array([input_dim], dtype=np.int64),
        'Output_Dim': np.array([output_dim], dtype=np.int64),
        # é€æ ·æœ¬å¯¼å‡ºï¼ˆé¡ºåºä¸ all_samples å®Œå…¨ä¸€è‡´ï¼‰
        'P_Pred_Flat_RI': p_pred_flat_ri,
        'P_True_Flat_RI': p_true_flat_ri,
        'SNR_dB': np.array(snr_db_list, dtype=np.float64),
        'Noise_Power': np.array(noise_power_list, dtype=np.float64),
        'Group_ID': np.array(group_id_list, dtype=np.float64),
        'User_Indices': user_indices,
        # æŒ‰SNRç»Ÿè®¡ç»“æœï¼ˆåŸæœ‰ï¼‰
        'SNR_Axis': np.array(snr_list),
        'MSE_Curve': np.array(avg_mse_list),
        'Sim_Curve': np.array(avg_sim_list),
        # å¦‚æœéœ€è¦åœ¨MATLABé‡Œåšæ›´ç»†è‡´çš„åˆ†æï¼ˆå¦‚CDFå›¾ï¼‰ï¼Œå¯ä»¥ä½¿ç”¨ä¸‹é¢çš„åŸå§‹æ•°æ®
        # æ³¨æ„ï¼šç”±äºä¸åŒSNRæ ·æœ¬æ•°å¯èƒ½ç¨æœ‰ä¸åŒï¼Œscipyä¿å­˜è¿™ç§éå¯¹é½æ•°æ®é€šå¸¸ç”¨object array
        'Raw_MSE_Distribution': np.array(raw_mse_data, dtype=object),
        'Raw_Sim_Distribution': np.array(raw_sim_data, dtype=object)
    }

    sio.savemat(OUTPUT_FILE, export_data)
    print(f"\nâœ… æ•°æ®å·²å¯¼å‡ºè‡³: {OUTPUT_FILE}")
if __name__ == '__main__':
    main()