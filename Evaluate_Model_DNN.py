import sys
import os
import torch
import torch.nn as nn
import scipy.io as sio
import numpy as np
from collections import defaultdict

# ================= é…ç½®åŒºåŸŸ =================
MODEL_PATH = 'DFDCA_DNN_Model_TrainBatch1to5_-10to20db_gap5db_4096hidden_500epoch.pth'                  # è®­ç»ƒå¥½çš„æ¨¡å‹

DATA_DIR = r'D:\CodeSpace\CodeOfMMSE_xUser_re_OnlyTrainToTrain\Data'
TEST_FILES_NAME = [
'TrainData_Batch_1.mat',
# 'TrainData_Batch_2.mat',
]
TEST_FILES = [os.path.join(DATA_DIR, f) for f in TEST_FILES_NAME]

RESULT_DIR = r'D:\CodeSpace\CodeOfMMSE_xUser_re_OnlyTrainToTrain\Result_P'
OUTPUT_FILE_NAME = 'DFDCA_Evaluation_Results_TrainBatch1to5_test1_4096hidden_500epoch.mat'        # å¯¼å‡ºçš„ç»“æœæ–‡ä»¶
OUTPUT_FILE = os.path.join(RESULT_DIR, OUTPUT_FILE_NAME)

HIDDEN_SIZE = 4096                                  # å¿…é¡»ä¸ Model.py ä¸€è‡´
DEVICE = torch.device("cuda" if torch.cuda.is_available() else "cpu")
# ===========================================

# 1. å®šä¹‰ç½‘ç»œç»“æ„ (å¿…é¡»ä¸è®­ç»ƒä»£ç å®Œå…¨ä¸€è‡´)
class ChannelNet(nn.Module):
    def __init__(self, input_dim, output_dim):
        super(ChannelNet, self).__init__()
        self.model = nn.Sequential(
            nn.Linear(input_dim, HIDDEN_SIZE),
            nn.BatchNorm1d(HIDDEN_SIZE),
            nn.ReLU(),
            nn.Linear(HIDDEN_SIZE, HIDDEN_SIZE // 2),
            nn.BatchNorm1d(HIDDEN_SIZE // 2),
            nn.ReLU(),
            nn.Linear(HIDDEN_SIZE // 2, HIDDEN_SIZE // 4),
            nn.ReLU(),
            nn.Linear(HIDDEN_SIZE // 4, output_dim)
        )

    def forward(self, x):
        return self.model(x)

def calculate_metrics(p_pred_complex, p_true_complex):
    """ è®¡ç®—å•ä¸ªæ ·æœ¬çš„ MSE å’Œ ä½™å¼¦ç›¸ä¼¼åº¦ """
    # å±•å¹³ä¸ºå‘é‡
    pred_flat = p_pred_complex.flatten()
    true_flat = p_true_complex.flatten()

    # 1. MSE è®¡ç®—
    diff = pred_flat - true_flat
    mse = np.mean(np.abs(diff) ** 2)

    # 2. ä½™å¼¦ç›¸ä¼¼åº¦è®¡ç®— (è€ƒè™‘å¤æ•°å…±è½­)
    # Sim = |a . b*| / (|a| * |b|)
    dot_product = np.abs(np.vdot(pred_flat, true_flat)) 
    norm_pred = np.linalg.norm(pred_flat)
    norm_true = np.linalg.norm(true_flat)
    
    if norm_pred == 0 or norm_true == 0:
        similarity = 0.0
    else:
        similarity = dot_product / (norm_pred * norm_true)

    return mse, similarity


def _extract_scalar(sample, field_name, default=None):
    if field_name not in sample.dtype.names:
        return default
    try:
        return float(np.array(sample[field_name]).flat[0])
    except Exception:
        return default


def _extract_user_indices(sample, usrnum=None):
    if 'User_Indices' not in sample.dtype.names:
        return None
    arr = np.array(sample['User_Indices']).astype(np.int64, copy=False).reshape(-1)
    if usrnum is not None and arr.size != usrnum:
        if arr.size > usrnum:
            arr = arr[:usrnum]
        else:
            arr = np.pad(arr, (0, usrnum - arr.size), mode='constant', constant_values=0)
    return arr


def p_flat_ri_to_matrices(y_flat_ri, usrnum, frenum):
    """å°† DNN è¾“å‡ºçš„å±•å¹³ RI æ‹¼æ¥å‘é‡é€†å˜æ¢å›çŸ©é˜µå½¢å¼ã€‚

    è®­ç»ƒæ—¶æ ‡ç­¾æ„é€ é€»è¾‘ï¼ˆè§ Model_DNN.pyï¼‰ï¼š
    y_vec = concat(P_Real.flatten(order='C'), P_Imag.flatten(order='C'))
    å› æ­¤è¿™é‡Œä¸¥æ ¼æŒ‰ç›¸åŒè§„åˆ™æ‹†åˆ† + reshapeã€‚
    """
    y_flat_ri = np.asarray(y_flat_ri)
    half = y_flat_ri.size // 2
    p_real = y_flat_ri[:half].reshape((usrnum, frenum), order='C')
    p_imag = y_flat_ri[half:].reshape((usrnum, frenum), order='C')
    return p_real, p_imag


def build_matlab_batch_buffer(samples):
    """ä¸¥æ ¼ä»¿ç…§ Generate_TrainingData_realverson.m çš„ Batch_Buffer(struct array) å­˜å‚¨å½¢å¼ã€‚"""
    dtype = [
        ('R_Real', 'O'),
        ('R_Imag', 'O'),
        ('P_Real', 'O'),
        ('P_Imag', 'O'),
        ('P_Real_Pred', 'O'),
        ('P_Imag_Pred', 'O'),
        ('User_Indices', 'O'),
        ('Noise_Power', 'O'),
        ('SNR_dB', 'O'),
        ('Group_ID', 'O'),
    ]
    batch_buffer = np.empty((1, len(samples)), dtype=dtype)
    for i, s in enumerate(samples):
        batch_buffer[0, i]['R_Real'] = np.asarray(s['R_Real'])
        batch_buffer[0, i]['R_Imag'] = np.asarray(s['R_Imag'])
        batch_buffer[0, i]['P_Real'] = np.asarray(s['P_Real'])
        batch_buffer[0, i]['P_Imag'] = np.asarray(s['P_Imag'])
        batch_buffer[0, i]['P_Real_Pred'] = np.asarray(s['P_Real_Pred'])
        batch_buffer[0, i]['P_Imag_Pred'] = np.asarray(s['P_Imag_Pred'])
        # MATLAB ä¾§é€šå¸¸æ˜¯è¡Œå‘é‡ï¼›è¿™é‡Œå¼ºåˆ¶æˆ (1, usrnum)
        batch_buffer[0, i]['User_Indices'] = np.asarray(s['User_Indices'], dtype=np.int64).reshape(1, -1)
        # æ ‡é‡å­—æ®µæŒ‰ MATLAB ä¿å­˜ä¹ æƒ¯ç”¨ 1x1
        batch_buffer[0, i]['Noise_Power'] = np.asarray(s['Noise_Power'], dtype=np.float64).reshape(1, 1)
        batch_buffer[0, i]['SNR_dB'] = np.asarray(s['SNR_dB'], dtype=np.float64).reshape(1, 1)
        batch_buffer[0, i]['Group_ID'] = np.asarray(s['Group_ID'], dtype=np.float64).reshape(1, 1)
    return batch_buffer

def main():
    print(f"=== DFDCA æ¨¡å‹éªŒè¯ä¸æ•°æ®å¯¼å‡º ===")
    print(f"è®¾å¤‡: {DEVICE}")

    # --- 1. æ‰‹åŠ¨æŒ‡å®šå¹¶æ‹¼æ¥å¤šä¸ªæ•°æ®æºï¼ˆæŒ‰é¡ºåºæ‹¼æ¥ï¼›ç¡®ä¿å…ƒä¿¡æ¯ä¸€ä¸€å¯¹åº”ï¼‰ ---
    test_files = list(TEST_FILES)

    if not test_files:
        print("âŒ é”™è¯¯: TEST_FILES ä¸ºç©ºï¼Œè¯·åœ¨è„šæœ¬é¡¶éƒ¨æ‰‹åŠ¨å¡«å†™å¾…è¯„ä¼°çš„ .mat æ–‡ä»¶ååˆ—è¡¨ã€‚")
        return

    print(f"ğŸ“‚ å¾…è¯„ä¼°æ–‡ä»¶æ•°: {len(test_files)}")
    for f in test_files:
        print(f"   - {f}")
    
    # åˆå¹¶æ‰€æœ‰ Batch_Buffer
    all_samples = []
    total_samples = 0
    
    for test_file in test_files:
        try:
            if not os.path.exists(test_file):
                print(f"   âŒ {test_file}: æ–‡ä»¶ä¸å­˜åœ¨")
                continue
            mat_data = sio.loadmat(test_file)
            if 'Batch_Buffer' not in mat_data:
                print(f"   âŒ {test_file}: ä¸åŒ…å« Batch_Buffer")
                continue
            test_buffer = mat_data['Batch_Buffer']
            num_batch_samples = test_buffer.shape[1]
            
            # æå–å½“å‰æ–‡ä»¶çš„æ‰€æœ‰æ ·æœ¬
            for i in range(num_batch_samples):
                all_samples.append(test_buffer[0, i])
            
            total_samples += num_batch_samples
            print(f"   âœ… {test_file}: {num_batch_samples} ä¸ªæ ·æœ¬")
        except Exception as e:
            print(f"   âŒ {test_file}: è¯»å–å¤±è´¥ - {e}")
            continue
    
    if total_samples == 0:
        print(f"âŒ é”™è¯¯: æœªæˆåŠŸåŠ è½½ä»»ä½•æ ·æœ¬")
        return
    
    print(f"\nâœ… æˆåŠŸåˆå¹¶ {total_samples} ä¸ªæµ‹è¯•æ ·æœ¬")

    # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
    os.makedirs(RESULT_DIR, exist_ok=True)

    # --- 2. å‡†å¤‡æ¨¡å‹ ---
    # è¯»å–ç¬¬ä¸€ä¸ªæ ·æœ¬ä»¥ç¡®å®šè¾“å…¥è¾“å‡ºç»´åº¦
    sample_0 = all_samples[0]
    input_dim = sample_0['R_Real'].size + sample_0['R_Imag'].size
    output_dim = sample_0['P_Real'].size + sample_0['P_Imag'].size
    
    print(f"\nğŸ”§ æ¨¡å‹é…ç½®:")
    print(f"   è¾“å…¥ç»´åº¦: {input_dim}, è¾“å‡ºç»´åº¦: {output_dim}")
    print(f"   éšå±‚å®½åº¦: {HIDDEN_SIZE}")

    model = ChannelNet(input_dim, output_dim).to(DEVICE)
    
    if not os.path.exists(MODEL_PATH):
        print(f"âŒ é”™è¯¯: æ‰¾ä¸åˆ°æ¨¡å‹æ–‡ä»¶ {MODEL_PATH}")
        return

    model.load_state_dict(torch.load(MODEL_PATH, map_location=DEVICE))
    model.eval()
    print("âœ… æ¨¡å‹æƒé‡åŠ è½½å®Œæ¯•")

    # --- 3. æ¨ç†ä¸æŒ‡æ ‡è®¡ç®— + å¯¼å‡ºæ‰€éœ€åŸå§‹æ•°æ® ---
    # ä½¿ç”¨å­—å…¸å­˜å‚¨æŒ‰ SNR åˆ†ç»„çš„ç»“æœ
    results_by_snr = defaultdict(lambda: {'mse': [], 'sim': [], 'power': []})

    # é€æ ·æœ¬å¯¼å‡ºï¼ˆä¸ all_samples é¡ºåºä¸€ä¸€å¯¹åº”ï¼‰
    p_pred_flat_ri_list = []
    p_true_flat_ri_list = []
    snr_db_list = []
    noise_power_list = []
    group_id_list = []
    user_indices_list = []

    # ç”¨äºæœ€ç»ˆæŒ‰ generate è„šæœ¬æ ¼å¼å¯¼å‡ºçš„ Batch_Bufferï¼ˆä¿å­˜â€œé¢„æµ‹åâ€çš„ P çŸ©é˜µï¼‰
    batch_buffer_samples = []

    print("\nå¼€å§‹æ¨ç†è®¡ç®—...")
    with torch.no_grad():
        for i, sample in enumerate(all_samples):
            snr_val = _extract_scalar(sample, 'SNR_dB', default=np.nan)

            # # è¿‡æ»¤é€»è¾‘ï¼šåªæµ‹ 15 å’Œ 20 dB
            # if snr_val < 14:
            #     continue



            # è·å–æ•°æ®
            r_real = sample['R_Real']
            r_imag = sample['R_Imag']
            p_real_true = sample['P_Real']
            p_imag_true = sample['P_Imag']

            usrnum = int(p_real_true.shape[0]) if hasattr(p_real_true, 'shape') and np.ndim(p_real_true) >= 2 else 10
            total_p = int(np.size(p_real_true))
            if hasattr(p_real_true, 'shape') and np.ndim(p_real_true) >= 2:
                frenum = int(p_real_true.shape[1])
            else:
                if usrnum <= 0 or total_p % usrnum != 0:
                    raise ValueError(f"æ— æ³•ä» P_Real æ¨æ–­ç»´åº¦: size={total_p}, usrnum={usrnum}")
                frenum = int(total_p // usrnum)
            
    
            # é¢„å¤„ç†è¾“å…¥
            x_vec = np.concatenate((r_real.flatten(), r_imag.flatten()))
            x_tensor = torch.FloatTensor(x_vec).unsqueeze(0).to(DEVICE)

            #snrä½œä¸ºè¾“å…¥ç‰¹å¾æ—¶é‡‡ç”¨
            # x_feat = np.concatenate((r_real.flatten(), r_imag.flatten()))
            # snr_norm = snr_val / 20.0
            # x_vec = np.append(x_feat, snr_norm)
            # x_tensor = torch.FloatTensor(x_vec).unsqueeze(0).to(DEVICE)

            # æ¨¡å‹é¢„æµ‹
            y_pred_flat_ri = model(x_tensor).cpu().numpy().squeeze().astype(np.float64, copy=False)

            # åå¤„ç†ï¼šç”¨äºæŒ‡æ ‡è®¡ç®—çš„å¤æ•°å‘é‡ï¼ˆå±•å¹³ï¼‰
            mid = len(y_pred_flat_ri) // 2
            p_pred_complex = y_pred_flat_ri[:mid] + 1j * y_pred_flat_ri[mid:]
            p_true_complex = p_real_true.flatten(order='C') + 1j * p_imag_true.flatten(order='C')

            # è®¡ç®—æŒ‡æ ‡
            mse, sim = calculate_metrics(p_pred_complex, p_true_complex)
            
            # --- æ–°å¢ï¼šè®¡ç®—çœŸå®æ ‡ç­¾çš„åŠŸç‡ (æ¨¡çš„å¹³æ–¹) ---
            p_true_power = np.mean(np.abs(p_true_complex)**2)

            # --- æ”¶é›†å¯¼å‡ºæ•°æ®ï¼ˆä¿æŒå±•å¹³ï¼Œä¸å¤åŸä¸ºçŸ©é˜µï¼‰ ---
            p_pred_flat_ri_list.append(y_pred_flat_ri)
            p_true_flat_ri_list.append(
                np.concatenate((p_real_true.flatten(order='C'), p_imag_true.flatten(order='C'))).astype(np.float64, copy=False)
            )
            snr_db_list.append(snr_val)
            noise_power_list.append(_extract_scalar(sample, 'Noise_Power', default=np.nan))
            group_id_list.append(_extract_scalar(sample, 'Group_ID', default=np.nan))
            user_idx = _extract_user_indices(sample, usrnum=usrnum)
            user_indices_list.append(user_idx if user_idx is not None else np.zeros((usrnum,), dtype=np.int64))

            # ä»…ç”¨äºâ€œä¿å­˜â€çš„é€†æ“ä½œï¼šæŠŠé¢„æµ‹På‘é‡è½¬å›çŸ©é˜µå½¢å¼ï¼ˆä¿æŒæ¨¡å‹åŸå§‹è¾“å‡ºï¼Œä¸åšåŠŸç‡å½’ä¸€åŒ–ï¼‰
            p_pred_real_mat, p_pred_imag_mat = p_flat_ri_to_matrices(y_pred_flat_ri, usrnum=usrnum, frenum=frenum)

            # ä¸¥æ ¼ä»¿ç…§ generate å­˜å‚¨ï¼šæ¯æ¡æ ·æœ¬è¿½åŠ åˆ° Batch_Buffer
            batch_buffer_samples.append({
                'R_Real': r_real,
                'R_Imag': r_imag,
                # çœŸå€¼ï¼ˆä¿æŒä¸ generate è„šæœ¬å­—æ®µä¸€è‡´ï¼‰
                'P_Real': p_real_true,
                'P_Imag': p_imag_true,
                # é¢„æµ‹å€¼ï¼ˆæ–°å¢å­—æ®µï¼‰
                'P_Real_Pred': p_pred_real_mat,
                'P_Imag_Pred': p_pred_imag_mat,
                'User_Indices': user_idx if user_idx is not None else np.zeros((usrnum,), dtype=np.int64),
                'Noise_Power': _extract_scalar(sample, 'Noise_Power', default=np.nan),
                'SNR_dB': snr_val,
                'Group_ID': _extract_scalar(sample, 'Group_ID', default=np.nan),
            })

            # å­˜å…¥åˆ—è¡¨
            results_by_snr[snr_val]['mse'].append(mse)
            results_by_snr[snr_val]['sim'].append(sim)
            results_by_snr[snr_val]['power'].append(p_true_power) # <--- æ–°å¢è¿™è¡Œ

            if (i + 1) % 500 == 0:
                print(f"   å·²å¤„ç† {i + 1}/{total_samples} ...")

    # --- 4. æ±‡æ€»æ•°æ® ---
    snr_list = sorted(results_by_snr.keys())
    avg_mse_list = []
    avg_sim_list = []
    
    # è¿™é‡Œä¹Ÿå¯ä»¥é€‰æ‹©ä¿å­˜æ‰€æœ‰æ ·æœ¬çš„åŸå§‹æ•°æ®ï¼Œä»¥ä¾¿ç”»ç®±çº¿å›¾ç­‰ï¼Œ
    # ä½†é€šå¸¸ç”»æ€§èƒ½æ›²çº¿åªéœ€è¦å¹³å‡å€¼ã€‚è¿™é‡Œæˆ‘ä»¬ä¸¤è€…éƒ½å‡†å¤‡ã€‚
    raw_mse_data = [] # è¿™æ˜¯ä¸€ä¸ª cell ç±»ä¼¼çš„ç»“æ„åˆ—è¡¨
    raw_sim_data = []

    print("\n=== éªŒè¯ç»“æœ (å¹³å‡å€¼) ===")
    print(f"{'SNR (dB)':<10} | {'MSE':<10} | {'Similarity':<10}| {'True Power':<10}")
    print("-" * 50)

    for snr in snr_list:
        mses = results_by_snr[snr]['mse']
        sims = results_by_snr[snr]['sim']
        pwrs = results_by_snr[snr]['power'] # <--- è·å–åŠŸç‡åˆ—è¡¨
        
        avg_mse = np.mean(mses)
        avg_sim = np.mean(sims)
        avg_pwr = np.mean(pwrs)             # <--- è®¡ç®—å¹³å‡åŠŸç‡
        
        avg_mse_list.append(avg_mse)
        avg_sim_list.append(avg_sim)
        
        # æ”¶é›†åŸå§‹æ•°æ®ä»¥ä¾¿å¯¼å‡º (numpy array)
        raw_mse_data.append(np.array(mses))
        raw_sim_data.append(np.array(sims))

        print(f"{snr:<10} | {avg_mse:<10.5f} | {avg_sim:<10.5f}| {avg_pwr:<10.5f}")

    # --- 5. å¯¼å‡ºåˆ° .mat æ–‡ä»¶ ---
    # è¦æ±‚ï¼šä¸¥æ ¼ä»¿ç…§ generate è„šæœ¬ï¼Œä»…ä¿å­˜ Batch_Buffer(struct array)
    batch_buffer = build_matlab_batch_buffer(batch_buffer_samples)
    sio.savemat(OUTPUT_FILE, {'Batch_Buffer': batch_buffer})
    print(f"\nâœ… å·²æŒ‰ generate æ ¼å¼å¯¼å‡º Batch_Buffer è‡³: {OUTPUT_FILE}")
if __name__ == '__main__':
    main()