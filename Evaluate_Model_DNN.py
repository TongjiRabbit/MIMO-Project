import sys
import os
import torch
import torch.nn as nn
import scipy.io as sio
import numpy as np
from collections import defaultdict
import glob

# ================= é…ç½®åŒºåŸŸ =================
TEST_FILE_PATTERN = 'TestData_Batch_6.mat'  # æ”¯æŒæ‰¹é‡åˆå¹¶ï¼šè‡ªåŠ¨æŸ¥æ‰¾æ‰€æœ‰åŒ¹é…æ–‡ä»¶
MODEL_PATH = 'DFDCA_DNN_Colab_Model_TrainBatch1to5_-10to20gap5db_4096hidden_1000epoch.pth'                  # è®­ç»ƒå¥½çš„æ¨¡å‹
OUTPUT_FILE = 'DFDCA_Evaluation_Results_Colab_TrainBatch1to5_test6_4096hidden_1000epoch.mat'        # å¯¼å‡ºçš„ç»“æœæ–‡ä»¶
HIDDEN_SIZE = 8192                                  # å¿…é¡»ä¸ Model.py ä¸€è‡´
DEVICE = torch.device("cuda" if torch.cuda.is_available() else "cpu")
# ===========================================

# 1. å®šä¹‰ç½‘ç»œç»“æ„ (å¿…é¡»ä¸è®­ç»ƒä»£ç å®Œå…¨ä¸€è‡´)
class ChannelNet(nn.Module):
    def __init__(self, input_dim, output_dim):
        super(ChannelNet, self).__init__()
        self.layer1 = nn.Sequential(
            nn.Linear(input_dim, HIDDEN_SIZE),
            nn.BatchNorm1d(HIDDEN_SIZE),
            nn.ReLU()
        )
        self.layer2 = nn.Sequential(
            nn.Linear(HIDDEN_SIZE, 4096),
            nn.BatchNorm1d(4096),
            nn.ReLU()
        )
        self.output_layer = nn.Linear(4096, output_dim)

    def forward(self, x):
        x = self.layer1(x)
        x = self.layer2(x)
        return self.output_layer(x)

def calculate_metrics(p_pred_complex, p_true_complex):
    """ è®¡ç®—å•ä¸ªæ ·æœ¬çš„ MSE å’Œ ä½™å¼¦ç›¸ä¼¼åº¦ """
    # å±•å¹³ä¸ºå‘é‡
    pred_flat = p_pred_complex.flatten()
    true_flat = p_true_complex.flatten()

    # 1. MSE è®¡ç®—
    diff = pred_flat - true_flat
    mse = np.mean(np.abs(diff) ** 2)

    # 2. ä½™å¼¦ç›¸ä¼¼åº¦è®¡ç®— (è€ƒè™‘å¤æ•°å…±è½­)
    # Sim = |a . b*| / (|a| * |b|)
    dot_product = np.abs(np.vdot(pred_flat, true_flat)) 
    norm_pred = np.linalg.norm(pred_flat)
    norm_true = np.linalg.norm(true_flat)
    
    if norm_pred == 0 or norm_true == 0:
        similarity = 0.0
    else:
        similarity = dot_product / (norm_pred * norm_true)

    return mse, similarity

def main():
    print(f"=== DFDCA æ¨¡å‹éªŒè¯ä¸æ•°æ®å¯¼å‡º ===")
    print(f"è®¾å¤‡: {DEVICE}")

    # --- 1. è‡ªåŠ¨æŸ¥æ‰¾å¹¶åˆå¹¶æ‰€æœ‰åŒ¹é…çš„æµ‹è¯•æ•°æ® ---
    test_files = sorted(glob.glob(TEST_FILE_PATTERN))
    
    if not test_files:
        print(f"âŒ é”™è¯¯: æ‰¾ä¸åˆ°ä»»ä½•åŒ¹é…æ–‡ä»¶: {TEST_FILE_PATTERN}")
        return
    
    print(f"ğŸ“‚ å‘ç° {len(test_files)} ä¸ªæµ‹è¯•æ–‡ä»¶:")
    for f in test_files:
        print(f"   - {f}")
    
    # åˆå¹¶æ‰€æœ‰ Batch_Buffer
    all_samples = []
    total_samples = 0
    
    for test_file in test_files:
        try:
            mat_data = sio.loadmat(test_file)
            test_buffer = mat_data['Batch_Buffer']
            num_batch_samples = test_buffer.shape[1]
            
            # æå–å½“å‰æ–‡ä»¶çš„æ‰€æœ‰æ ·æœ¬
            for i in range(num_batch_samples):
                all_samples.append(test_buffer[0, i])
            
            total_samples += num_batch_samples
            print(f"   âœ… {test_file}: {num_batch_samples} ä¸ªæ ·æœ¬")
        except Exception as e:
            print(f"   âŒ {test_file}: è¯»å–å¤±è´¥ - {e}")
            continue
    
    if total_samples == 0:
        print(f"âŒ é”™è¯¯: æœªæˆåŠŸåŠ è½½ä»»ä½•æ ·æœ¬")
        return
    
    print(f"\nâœ… æˆåŠŸåˆå¹¶ {total_samples} ä¸ªæµ‹è¯•æ ·æœ¬")

    # --- 2. å‡†å¤‡æ¨¡å‹ ---
    # è¯»å–ç¬¬ä¸€ä¸ªæ ·æœ¬ä»¥ç¡®å®šè¾“å…¥è¾“å‡ºç»´åº¦
    sample_0 = all_samples[0]
    input_dim = sample_0['R_Real'].size + sample_0['R_Imag'].size
    output_dim = sample_0['P_Real'].size + sample_0['P_Imag'].size
    
    print(f"\nğŸ”§ æ¨¡å‹é…ç½®:")
    print(f"   è¾“å…¥ç»´åº¦: {input_dim}, è¾“å‡ºç»´åº¦: {output_dim}")
    print(f"   éšå±‚å®½åº¦: {HIDDEN_SIZE}")

    model = ChannelNet(input_dim, output_dim).to(DEVICE)
    
    if not os.path.exists(MODEL_PATH):
        print(f"âŒ é”™è¯¯: æ‰¾ä¸åˆ°æ¨¡å‹æ–‡ä»¶ {MODEL_PATH}")
        return

    model.load_state_dict(torch.load(MODEL_PATH, map_location=DEVICE))
    model.eval()
    print("âœ… æ¨¡å‹æƒé‡åŠ è½½å®Œæ¯•")

    # --- 3. æ¨ç†ä¸æŒ‡æ ‡è®¡ç®— ---
    # ä½¿ç”¨å­—å…¸å­˜å‚¨æŒ‰ SNR åˆ†ç»„çš„ç»“æœ
    results_by_snr = defaultdict(lambda: {'mse': [], 'sim': [], 'power': []})

    print("\nå¼€å§‹æ¨ç†è®¡ç®—...")
    with torch.no_grad():
        for i, sample in enumerate(all_samples):
            snr_val = float(sample['SNR_dB'].flat[0])

            # # è¿‡æ»¤é€»è¾‘ï¼šåªæµ‹ 15 å’Œ 20 dB
            # if snr_val < 14:
            #     continue



            # è·å–æ•°æ®
            r_real = sample['R_Real']
            r_imag = sample['R_Imag']
            p_real_true = sample['P_Real']
            p_imag_true = sample['P_Imag']
            
    
            # é¢„å¤„ç†è¾“å…¥
            x_vec = np.concatenate((r_real.flatten(), r_imag.flatten()))
            x_tensor = torch.FloatTensor(x_vec).unsqueeze(0).to(DEVICE)

            #snrä½œä¸ºè¾“å…¥ç‰¹å¾æ—¶é‡‡ç”¨
            # x_feat = np.concatenate((r_real.flatten(), r_imag.flatten()))
            # snr_norm = snr_val / 20.0
            # x_vec = np.append(x_feat, snr_norm)
            # x_tensor = torch.FloatTensor(x_vec).unsqueeze(0).to(DEVICE)

            # æ¨¡å‹é¢„æµ‹
            y_pred = model(x_tensor).cpu().numpy().squeeze()

            # åå¤„ç†ï¼šè¿˜åŸå¤æ•°
            mid = len(y_pred) // 2
            p_pred_complex = y_pred[:mid] + 1j * y_pred[mid:]
            p_true_complex = p_real_true.flatten() + 1j * p_imag_true.flatten()

            # è®¡ç®—æŒ‡æ ‡
            mse, sim = calculate_metrics(p_pred_complex, p_true_complex)
            
            # --- æ–°å¢ï¼šè®¡ç®—çœŸå®æ ‡ç­¾çš„åŠŸç‡ (æ¨¡çš„å¹³æ–¹) ---
            p_true_power = np.mean(np.abs(p_true_complex)**2)

            # å­˜å…¥åˆ—è¡¨
            results_by_snr[snr_val]['mse'].append(mse)
            results_by_snr[snr_val]['sim'].append(sim)
            results_by_snr[snr_val]['power'].append(p_true_power) # <--- æ–°å¢è¿™è¡Œ

            if (i + 1) % 500 == 0:
                print(f"   å·²å¤„ç† {i + 1}/{total_samples} ...")

    # --- 4. æ±‡æ€»æ•°æ® ---
    snr_list = sorted(results_by_snr.keys())
    avg_mse_list = []
    avg_sim_list = []
    
    # è¿™é‡Œä¹Ÿå¯ä»¥é€‰æ‹©ä¿å­˜æ‰€æœ‰æ ·æœ¬çš„åŸå§‹æ•°æ®ï¼Œä»¥ä¾¿ç”»ç®±çº¿å›¾ç­‰ï¼Œ
    # ä½†é€šå¸¸ç”»æ€§èƒ½æ›²çº¿åªéœ€è¦å¹³å‡å€¼ã€‚è¿™é‡Œæˆ‘ä»¬ä¸¤è€…éƒ½å‡†å¤‡ã€‚
    raw_mse_data = [] # è¿™æ˜¯ä¸€ä¸ª cell ç±»ä¼¼çš„ç»“æ„åˆ—è¡¨
    raw_sim_data = []

    print("\n=== éªŒè¯ç»“æœ (å¹³å‡å€¼) ===")
    print(f"{'SNR (dB)':<10} | {'MSE':<10} | {'Similarity':<10}| {'True Power':<10}")
    print("-" * 50)

    for snr in snr_list:
        mses = results_by_snr[snr]['mse']
        sims = results_by_snr[snr]['sim']
        pwrs = results_by_snr[snr]['power'] # <--- è·å–åŠŸç‡åˆ—è¡¨
        
        avg_mse = np.mean(mses)
        avg_sim = np.mean(sims)
        avg_pwr = np.mean(pwrs)             # <--- è®¡ç®—å¹³å‡åŠŸç‡
        
        avg_mse_list.append(avg_mse)
        avg_sim_list.append(avg_sim)
        
        # æ”¶é›†åŸå§‹æ•°æ®ä»¥ä¾¿å¯¼å‡º (numpy array)
        raw_mse_data.append(np.array(mses))
        raw_sim_data.append(np.array(sims))

        print(f"{snr:<10} | {avg_mse:<10.5f} | {avg_sim:<10.5f}| {avg_pwr:<10.5f}")

    # --- 5. å¯¼å‡ºåˆ° .mat æ–‡ä»¶ ---
    export_data = {
        'SNR_Axis': np.array(snr_list),
        'MSE_Curve': np.array(avg_mse_list),
        'Sim_Curve': np.array(avg_sim_list),
        # å¦‚æœéœ€è¦åœ¨MATLABé‡Œåšæ›´ç»†è‡´çš„åˆ†æï¼ˆå¦‚CDFå›¾ï¼‰ï¼Œå¯ä»¥ä½¿ç”¨ä¸‹é¢çš„åŸå§‹æ•°æ®
        # æ³¨æ„ï¼šç”±äºä¸åŒSNRæ ·æœ¬æ•°å¯èƒ½ç¨æœ‰ä¸åŒï¼Œscipyä¿å­˜è¿™ç§éå¯¹é½æ•°æ®é€šå¸¸ç”¨object array
        'Raw_MSE_Distribution': np.array(raw_mse_data, dtype=object),
        'Raw_Sim_Distribution': np.array(raw_sim_data, dtype=object)
    }

    sio.savemat(OUTPUT_FILE, export_data)
    print(f"\nâœ… æ•°æ®å·²å¯¼å‡ºè‡³: {OUTPUT_FILE}")
if __name__ == '__main__':
    main()